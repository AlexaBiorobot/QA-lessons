#!/usr/bin/env python3
import time
import io
import os

import streamlit as st
import pandas as pd
import requests
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from gspread.exceptions import APIError

# === Constants ===
LESSONS_SS       = "1_S-NyaVKuOc0xK12PBAYvdIauDBq9mdqHlnKLfSYNAE"
LATAM_GID        = "0"
BRAZIL_GID       = "835553195"

RATING_LATAM_SS  = "16QrbLtzLTV6GqyT8HYwzcwYIsXewzjUbM0Jy5i1fENE"
RATING_BRAZIL_SS = "1HItT2-PtZWoldYKL210hCQOLg3rh6U1Qj6NWkBjDjzk"
RATING_SHEET     = "Rating"

QA_LATAM_SS      = RATING_LATAM_SS
QA_BRAZIL_SS     = RATING_BRAZIL_SS
QA_SHEET         = "QA - Lesson evaluation"

REPL_SS          = "1LF2NrAm8J3c43wOoumtsyfQsX1z0_lUQVdByGSPe27U"
REPL_SHEET       = "Replacement"

# === Auth & helpers ===
@st.cache_data(show_spinner=False)
def get_client():
    import json
    sa_json = os.getenv("GCP_SERVICE_ACCOUNT") or st.secrets["GCP_SERVICE_ACCOUNT"]
    info    = json.loads(sa_json)
    scope   = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive",
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(info, scope)
    return gspread.authorize(creds)

def api_retry(func, *args, max_attempts=5, initial_backoff=1.0, **kwargs):
    backoff = initial_backoff
    for i in range(1, max_attempts+1):
        try:
            return func(*args, **kwargs)
        except APIError as e:
            code = getattr(e.response, "status_code", None) or getattr(e.response, "status", None)
            if code and 500 <= int(code) < 600 and i < max_attempts:
                time.sleep(backoff)
                backoff *= 2
                continue
            raise

def load_public_lessons(ss_id: str, gid: str, region: str) -> pd.DataFrame:
    """Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð¿ÑƒÐ±Ð»Ð¸Ñ‡Ð½Ð¾ Ñ‡ÐµÑ€ÐµÐ· CSV-export, fallback Ð½Ð° GSpread ÐµÑÐ»Ð¸ Ð¿ÑƒÑÑ‚Ð¾.
       ÐŸÑ€Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ð¸ Ð½ÑƒÐ¶Ð½Ñ‹Ñ… ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº â€” Ð¿Ð¾Ð´ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð¿ÑƒÑÑ‚Ñ‹Ðµ."""
    url = f"https://docs.google.com/spreadsheets/d/{ss_id}/export?format=csv&gid={gid}"
    try:
        resp = requests.get(url, timeout=20)
        resp.raise_for_status()
        raw = pd.read_csv(io.StringIO(resp.text), dtype=str)
    except (pd.errors.EmptyDataError, requests.RequestException):
        raw = load_sheet_values(ss_id, sheet_name=None, gid=gid)

    # Ð½ÑƒÐ¶Ð½Ñ‹Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð² Ð²Ð°ÑˆÐµÐ¼ GS-ÑÐ¿Ð¸ÑÐºÐµ
    wanted = ["R", "Q", "B", "J", "N", "G", "H", "Y"]
    # ÐµÑÐ»Ð¸ ÐºÑ‚Ð¾-Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð¿Ð°Ð» â€” Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ Ñ NaN (Ð¸Ð»Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¾Ð¹)
    for col in wanted:
        if col not in raw.columns:
            raw[col] = pd.NA
    # Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¼Ð¾Ð¶Ð½Ð¾ Ñ€ÐµÐ·Ð°Ñ‚ÑŒ Ð¿Ð¾ Ð½Ð¸Ð¼
    df = raw[wanted]
    df.columns = [
        "Tutor name","Tutor ID","Date of the lesson","Group",
        "Course ID","Module","Lesson","Lesson Link"
    ]

    df["Region"] = region
    df["Date of the lesson"] = pd.to_datetime(df["Date of the lesson"], errors="coerce")
    return df

def load_sheet_values(ss_id: str, sheet_name: str = None, gid: str = None) -> pd.DataFrame:
    """Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¾Ðµ Ñ‡Ñ‚ÐµÐ½Ð¸Ðµ: ÐµÑÐ»Ð¸ sheet_name Ð·Ð°Ð´Ð°Ð½ â€” Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸, Ð¸Ð½Ð°Ñ‡Ðµ â€” Ð¿Ð¾ gid."""
    client = get_client()
    sh     = api_retry(client.open_by_key, ss_id)
    if sheet_name:
        ws = api_retry(sh.worksheet, sheet_name)
    else:
        # Ð¸Ñ‰ÐµÐ¼ Ð²ÐºÐ»Ð°Ð´ÐºÑƒ Ð¿Ð¾ numeric gid
        ws = next(w for w in api_retry(sh.worksheets) if str(w.id) == str(gid))
    rows = api_retry(ws.get_all_values)
    maxc = max(len(r) for r in rows)
    header = rows[0] + [""]*(maxc - len(rows[0]))
    data = [r + [""]*(maxc - len(r)) for r in rows[1:]]
    return pd.DataFrame(data, columns=header)

# === ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ ÑÐ±Ð¾Ñ€ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… ===
@st.cache_data(show_spinner=True)
def build_df() -> pd.DataFrame:
    # 1) ÑƒÑ€Ð¾ÐºÐ¸
    df_lat = load_public_lessons(LESSONS_SS, LATAM_GID,  "LATAM")
    df_brz = load_public_lessons(LESSONS_SS, BRAZIL_GID, "Brazil")
    df     = pd.concat([df_lat, df_brz], ignore_index=True)

    # 2) Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³
    def load_rating(ss_id: str) -> pd.DataFrame:
        client = get_client()
        sh     = api_retry(client.open_by_key, ss_id)
        ws     = api_retry(sh.worksheet, RATING_SHEET)
        rows   = api_retry(ws.get_all_values)
        # Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº â€” Ð² ÑÑ‚Ñ€Ð¾ÐºÐµ 1, Ð´Ð°Ð½Ð½Ñ‹Ðµ â€” ÑÐ¾ 2-Ð¹
        header = rows[1]
        data   = rows[2:]
        maxc   = max(len(header), *(len(r) for r in data))
        header = header + [""]*(maxc - len(header))
        data   = [r + [""]*(maxc - len(r)) for r in data]
        r = pd.DataFrame(data, columns=header)
        # Ð²Ñ‹Ð±Ñ€Ð°Ð»Ð¸ Ð½ÑƒÐ¶Ð½Ñ‹Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ (Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð² Ð²Ð°ÑˆÐµÐ¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ!)
        cols = [
            "Tutor ID",   # Ð¸Ð»Ð¸ "ID" â€” Ð¿Ð¾Ð´ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ Ñƒ Ð²Ð°Ñ Ð²Ð¾ Ð²Ñ‚Ð¾Ñ€Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐµ
            "Rating",
            "Num of QA scores",
            "Num of QA scores (last 90 days)",
            "Average QA score",
            "Average QA score (last 2 scores within last 90 days)",
            "Average QA marker",
            "Average QA marker (last 2 markers within last 90 days)",
        ]
        # ÐµÑÐ»Ð¸ Ñƒ Ð²Ð°Ñ Ñ‚Ð°Ð¼ ÑÑ‚Ð¾Ð»Ð±ÐµÑ† Ð½Ð°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ "ID", Ñ‚Ð¾:
        if "ID" in r.columns and "Tutor ID" not in r.columns:
            r = r.rename(columns={"ID": "Tutor ID"})
        return r[cols]

    r_lat = load_rating(RATING_LATAM_SS)
    r_brz = load_rating(RATING_BRAZIL_SS)

    # merge Ð¿Ð¾ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ñƒ
    df = (
        df
        .merge(r_lat, on="Tutor ID", how="left")
        .where(df["Region"]=="LATAM", df)
        .merge(r_brz, on="Tutor ID", how="left")
        .where(df["Region"]=="Brazil", df)
    )

    # 3) QA Ð¾Ñ†ÐµÐ½ÐºÐ¸ (ÑˆÐ°Ð¿ÐºÐ° Ð² Ð¿ÐµÑ€Ð²Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐµ)
    def load_qa(ss_id: str) -> pd.DataFrame:
        q = load_sheet_values(ss_id, sheet_name=QA_SHEET)
        q["Date"] = pd.to_datetime(q["B"], errors="coerce")
        return (
            q[["A","E","Date","C","D"]]
             .rename(columns={"A":"Tutor ID","E":"Group","C":"QA score","D":"QA marker"})
        )

    q_lat = load_qa(QA_LATAM_SS)
    q_brz = load_qa(QA_BRAZIL_SS)

    df = (
        df
        .merge(q_lat, on=["Tutor ID","Group","Date of the lesson"], how="left")
        .where(df["Region"]=="LATAM", df)
        .merge(q_brz, on=["Tutor ID","Group","Date of the lesson"], how="left")
        .where(df["Region"]=="Brazil", df)
    )

    # 4) Replacement
    rp = load_sheet_values(REPL_SS, sheet_name=REPL_SHEET)
    rp["Date"]  = pd.to_datetime(rp["D"], errors="coerce")
    rp["Group"] = rp["F"]
    rp = rp[["Date","Group"]].assign(**{"Replacement or not":"Replacement/Postponement"})

    df = df.merge(
        rp,
        left_on=["Date of the lesson","Group"],
        right_on=["Date","Group"],
        how="left"
    )
    df["Replacement or not"] = df["Replacement or not"].fillna("")

    return df

# === Streamlit UI ===
st.set_page_config(layout="wide")
df = build_df()

st.sidebar.header("Filters")
filters = {}
for col in df.columns:
    if df[col].dtype == object:
        opts = sorted(df[col].dropna().unique())
        filters[col] = st.sidebar.multiselect(col, opts, default=opts)

mask = pd.Series(True, index=df.index)
for c, sel in filters.items():
    mask &= df[c].isin(sel)
dff = df[mask]

st.title("ðŸ“Š QA & Rating Dashboard")
st.dataframe(dff, use_container_width=True)

# Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ CSV
csv = dff.to_csv(index=False)
st.download_button("ðŸ“¥ Download CSV", csv, "qa_dashboard.csv", "text/csv")
